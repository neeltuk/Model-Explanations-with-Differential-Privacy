# Model-Explanations-with-Differential-Privacy
This is the repository containing the supplementary material for the paper [Model Explanations with Differential Privacy]() by [Neel Patel](https://scholar.google.com/citations?user=CJIh_QIAAAAJ&hl=en), [Reza Shokri](https://www.comp.nus.edu.sg/~reza/) and [Yair Zick](https://people.umass.edu/yzick/index.html).

# Abstract
Using machine learning models in critical decision-making processes has given rise to a call for algorithmic transparency. Model explanations, however, might leak information about the sensitive data used to train and explain the model, undermining data privacy. We focus on black-box feature-based model explanations, which locally approximate the model around the point of interest, using training (or similarly distributed) data. We design and evaluate the effect of differential privacy mechanisms on explanation quality. We use existing differentially private algorithms during model training. However, to protect data privacy during the explanation time, we design an adaptive differentially private algorithm, which finds the minimal privacy budget required to produce accurate explanations, protecting the data used during the local approximation. We also show that this mechanism slightly amplifies the privacy guarantees of the differentially private training algorithm. We evaluate the impact of the randomness in differential privacy algorithms on the fidelity of model explanations, analyzing both their  theoretical and empirical performance.
